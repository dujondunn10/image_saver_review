{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elroy-aeontsolutions/image_saver/blob/main/Scrape_and_Save.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scrape and Save\n",
        "This notebook was written to automate the scraping and saving of images from the internet."
      ],
      "metadata": {
        "id": "d450ErNypDqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We begin by importing the relevant modules. Requests will be used to access the urls and BeautifulSoup will be used to parse data for the image urls. Finally, os will be used to create the directory into which images will be saved."
      ],
      "metadata": {
        "id": "J6ispo-HpIaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJirIrmXoTV2"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to get the html as text from the url."
      ],
      "metadata": {
        "id": "tWwdRu85pNfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "htmldata = requests.get(\"https://www.geeksforgeeks.org/\").text"
      ],
      "metadata": {
        "id": "1HPsukMuotph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we use BeautifulSoup to parse the html text data for the image links and then save them in a list."
      ],
      "metadata": {
        "id": "rTSC4tAMpQ6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(htmldata, 'html.parser') \n",
        "img_urls = [item['src'] for item in soup.find_all('img')]"
      ],
      "metadata": {
        "id": "gBoYAUVco0QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "os is used to a make the folder into which the files will be saved. A list of directory names corresponding to the category of images should be created."
      ],
      "metadata": {
        "id": "ih2XO_YhpU-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dirs = ['test_dir']\n",
        "\n",
        "os.mkdir(dirs[0])"
      ],
      "metadata": {
        "id": "XcT_zdUro29_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, iterating through the list of image urls, download and save the images in the appropriate directory. "
      ],
      "metadata": {
        "id": "O1bOThnppZHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, url in enumerate(img_urls):\n",
        "  try: response = requests.get(url)\n",
        "  except: pass\n",
        "  \n",
        "  if response.status_code:\n",
        "    with open('{0}/test_save_{1}.png'.format(dirs[0], i), 'wb') as fp:\n",
        "          fp.write(response.content)"
      ],
      "metadata": {
        "id": "ATCFTGyco5Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll need to change this script in the following ways\n",
        "\n",
        "\n",
        "* It will need to be able to download text from an accessible website or google images; https://www.thecarconnection.com/ is not accessible via this method.\n",
        "* Depending on the website, the script may need to be able to perform searches \n",
        "* We will need to direct it to save the images in a Google Cloud bucket directory.\n",
        "\n"
      ],
      "metadata": {
        "id": "KAnvn2rvqu_Z"
      }
    }
  ]
}